<p>
    <span style="color:#00B050;"><strong>
    前段时间在研究扫描器的问题，在涉及域名采集这块时， 突然有了一些特别的想法，所以单独将这个模块提取出来，做成了一套独立系统。
    </strong></span>
</p>

<p>对于域名采集技术，市面上大概有这样几种：</p>

<ul>
  <li>DNS域传送泄露</li>
  <li>接口查询（包括aizhan，shodan等）</li>
  <li>字典枚举</li>
  <li>Github泄露</li>
  <li>搜索引擎泄露</li>
  <li>SSL/TLS证书泄露</li>
  <li>DNS历史记录泄露</li>
  <li>置换扫描枚举法</li>
  <li>互联网自治系统号码(ASN)枚举</li>
  <li>NSEC记录枚举</li>
  <li>互联网项目数据集枚举</li>
</ul>

<p>不过这里要谈的显然不是这种，尽管自研的扫描器里已经集成了前面说的这些，今天的主角是域名采集爬虫。</p>

<p>那么何谓域名采集爬虫呢，其实也是老概念。我们要先从一个URL或者多个URL入口进行爬取。在开始，需要设定好爬行深度和允许爬行的根域名，通过不断地迭代存取和过滤，直到爬取完所有可触及的域名为止。</p>

<p>这样的域名采集方法，较其他技术优势在于：</p>

<ul>
  <li>能采到不被搜索引擎收录的可用域名。</li>
  <li>囊括范围广，除去CDN影响，能更多地去收集目标资产。</li>
  <li>细致入微，在域名采集普及的时代，厂商一般子域名都会多加注意起名，这样做能多收获一些隐藏域名。</li>
  <li>可分布式，相对于普通的单机大字典爆破，可以选择性节省更多的时间。</li>
</ul>

<p>当然讲了这么多，其劣势也很明显：</p>

<ul>
  <li>将耗费更多的时间和各类资源，即使采用了分布式，由于需要考虑部分目标主机的脆弱性，建立的连接数还是有限的。</li>
  <li>容易被封，WAF和各种IDS的规则在检测到爬虫后，可能会直接封禁IP，不过这点可以通过技术手段缓解。</li>
  <li>不易部署，相对于常用的域名接口查询和爆破，这点的劣势还是相当明显的。</li>
  <li>比较鸡肋，没有太多Team会专门为了爬取域名单独建立一个可用的爬虫体系，一般是扫描器只兼容了传统接口。</li>
</ul>

<p>优劣对比还是比较明显的，这里不多做探讨，下面纯技术介绍。</p>

<p>这里的系统采用的是scrapy+django+mongodb，每采集好一批数据后，将存入mongodb，其中的数据包括：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>页面源URL
子域名
根域名

</code></pre>
</div>

<p>后续其他项目将会解析生成的所有子域名，最后再进行资产汇总计算。这些本不属于此项目，不再细说。</p>

<p>另外，在采集过程中，爬虫会在中间件（合规的做法如此，笔者则是直接在爬虫文件里进行的过滤），根据条件过滤重复和不合规的URL。</p>

<p>代码其实很简单，现在已有的是前台查询+后台爬虫（命令行）的形式。后期如果项目可用，会加上前台scrapyd发布任务+MMQ分布式队列缓存。</p>

<p>另外，以后也考虑集成传统接口、泄露查询和枚举模块。</p>

<p>至于为啥现在没有做，因为懒。</p>

<p>代码由于还需要优化，暂时没有放出，以后会补上。</p>

<p>待续。</p>
